{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b649278e",
   "metadata": {},
   "source": [
    "#follow this to install prismnet\n",
    "https://github.com/kuixu/PrismNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e17a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "import prismnet.model as arch\n",
    "from prismnet import train, validate, inference, log_print, compute_saliency, compute_saliency_img, compute_high_attention_region\n",
    "#compute_high_attention_region\n",
    "\n",
    "# from prismnet.engine.train_loop import \n",
    "from prismnet.model.utils import GradualWarmupScheduler\n",
    "from prismnet.loader import SeqicSHAPE\n",
    "from prismnet.utils import datautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0830b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # out dir\n",
    "\n",
    "# identity   = args.p_name+'_'+args.arch+\"_\"+args.mode # 441_PUM2_K562_sub4509_PrismNet_pu.metrics\n",
    "# datautils.make_directory(args.out_dir,\"out/\")\n",
    "# model_dir  = datautils.make_directory(args.out_dir,\"out/models\")\n",
    "# model_path = os.path.join(model_dir, identity+\"_{}.pth\")\n",
    "\n",
    "# if args.tfboard:\n",
    "#     tfb_dir  = datautils.make_directory(args.out_dir,\"out/tfb\")\n",
    "#     writer = SummaryWriter(tfb_dir)\n",
    "# else:\n",
    "#     writer = None\n",
    "# # fix random seed\n",
    "# fix_seed(args.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1218a44d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "premask (138498, 5) (138498, 137)\n",
      "premask (137998, 5) (137998, 137)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "outstem = 'K562_rep6'\n",
    "megaoutput = pd.read_csv(f'../data/ABC_data/{outstem}.megaoutputs.tsv', sep = '\\t', index_col = 0)\n",
    "mask = pd.read_csv(f'../data/ABC_data/{outstem}.genome_mask.csv', index_col = 0)\n",
    "seq = pd.read_csv(f'../data/ABC_data/tsv/{outstem}.DDX3.tsv', sep = '\\t', names = ['chrom', 'name', \n",
    "                                                                                 'seq', 'struct', 'label', 'start'])\n",
    "seq.set_index('name', inplace = True)\n",
    "print('premask', seq.shape, megaoutput.shape)\n",
    "# remove mask\n",
    "megaoutput = megaoutput.loc[~megaoutput.index.isin(mask.index)]\n",
    "seq = seq.loc[~seq.index.isin(mask.index)]\n",
    "print('premask', seq.shape, megaoutput.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa595cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=seq['seq'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3b0696d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prismnet.utils import datautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "651132bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot = datautils.convert_one_hot(seq.loc[megaoutput.index, 'seq'], max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1d53633",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137998, 4, 100)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot.shape # N, 4, max_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f56775e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = one_hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54c692bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets: predict binary\n",
    "target_col = megaoutput.columns[(megaoutput.columns.str.startswith('logLR'))&(megaoutput.columns.str.contains(outstem))]\n",
    "target_df = megaoutput[target_col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d56a7f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "sumstat = target_df.describe().T\n",
    "max_abs_val = pd.concat([sumstat['max'].abs(),sumstat['min'].abs()], axis = 1).max(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7703ed2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_df_scaled = target_df.div(max_abs_val, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8641f12d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD4CAYAAADy46FuAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8rg+JYAAAACXBIWXMAAAsTAAALEwEAmpwYAAAU2UlEQVR4nO3df6zd9X3f8edrOEmdpBB+hDtm05k2XluCFzV4hDVbdTdXxUmqmUkguaPBRJ6sZTRLJ0uryaRFWoUE09K0aCOVFTJMFoV4NBreUtoy6F02FUwhTeMAo3iBgYcHpVCKs4Xmkvf+OJ+7Xd9cf+499x7fe2yeD+nofM/7+/18zuejr49f9/v9nvu9qSokSTqRv7DaA5AkjTeDQpLUZVBIkroMCklSl0EhSepas9oDGLXzzjuvNmzYMFSbb3/727ztbW87OQNaYafTXOD0mo9zGU/OZeCRRx55sareOd+60y4oNmzYwMMPPzxUm6mpKSYnJ0/OgFbY6TQXOL3m41zGk3MZSPI/TrTOU0+SpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqSu0+43s09VG/Z8ZST97N40zXVD9vX0TR8ayXtLOj15RCFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6FgyKJJ9L8kKSb86qnZPk3iRPtuezZ627IcnhJE8kuWJW/dIkh9q6W5Kk1d+S5EutfjDJhlltdrT3eDLJjpHNWpK0aIs5orgd2Dqntge4r6o2Ave11yS5GNgOvLu1uTXJGa3NZ4BdwMb2mOlzJ/ByVb0L+DRwc+vrHOCTwPuAy4BPzg4kSdLKWDAoquqrwEtzytuAfW15H3DlrPqdVfVaVT0FHAYuS3IBcGZVPVBVBdwxp81MX3cBW9rRxhXAvVX1UlW9DNzL9weWJOkkW+qfQp2oqqMAVXU0yfmtvg54cNZ2R1rtu215bn2mzbOtr+kkrwDnzq7P0+Y4SXYxOFphYmKCqampoSZz7NixoduM2u5N0yPpZ2Lt8H2t9tx7xmHfjIpzGU/OZWGj/pvZmadWnfpS2xxfrNoL7AXYvHlzTU5OLjjQ2aamphi2zagN+3euT2T3pmk+dWi43fr0NZMjee+TYRz2zag4l/HkXBa21G89Pd9OJ9GeX2j1I8CFs7ZbDzzX6uvnqR/XJska4CwGp7pO1JckaQUtNSgOADPfQtoB3D2rvr19k+kiBhetH2qnqV5Ncnm7/nDtnDYzfV0F3N+uY/w28DNJzm4XsX+m1SRJK2jBcxRJvghMAuclOcLgm0g3AfuT7ASeAa4GqKpHk+wHHgOmgeur6vXW1UcZfINqLXBPewDcBnw+yWEGRxLbW18vJfll4Pfbdv+8quZeVJcknWQLBkVV/dwJVm05wfY3AjfOU38YuGSe+ndoQTPPus8Bn1tojJKkk8ffzJYkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6lhUUSf5xkkeTfDPJF5P8QJJzktyb5Mn2fPas7W9IcjjJE0mumFW/NMmhtu6WJGn1tyT5UqsfTLJhOeOVJA1vyUGRZB3wj4DNVXUJcAawHdgD3FdVG4H72muSXNzWvxvYCtya5IzW3WeAXcDG9tja6juBl6vqXcCngZuXOl5J0tIs99TTGmBtkjXAW4HngG3AvrZ+H3BlW94G3FlVr1XVU8Bh4LIkFwBnVtUDVVXAHXPazPR1F7Bl5mhDkrQy1iy1YVX9zyT/EngG+D/A71TV7ySZqKqjbZujSc5vTdYBD87q4kirfbctz63PtHm29TWd5BXgXODF2WNJsovBEQkTExNMTU0NNZdjx44N3WbUdm+aHkk/E2uH72u1594zDvtmVJzLeHIuC1tyULRrD9uAi4A/Bf5dkp/vNZmnVp16r83xhaq9wF6AzZs31+TkZGcY329qaoph24zadXu+MpJ+dm+a5lOHhtutT18zOZL3PhnGYd+MinMZT85lYcs59fTTwFNV9cdV9V3gy8BPAs+300m05xfa9keAC2e1X8/gVNWRtjy3flybdnrrLOClZYxZkjSk5QTFM8DlSd7arhtsAR4HDgA72jY7gLvb8gFge/sm00UMLlo/1E5TvZrk8tbPtXPazPR1FXB/u44hSVohy7lGcTDJXcDXgGngDxic/nk7sD/JTgZhcnXb/tEk+4HH2vbXV9XrrbuPArcDa4F72gPgNuDzSQ4zOJLYvtTxSpKWZslBAVBVnwQ+Oaf8GoOji/m2vxG4cZ76w8Al89S/QwsaSdLq8DezJUldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUtaygSPKOJHcl+W9JHk/y15Ock+TeJE+257NnbX9DksNJnkhyxaz6pUkOtXW3JEmrvyXJl1r9YJINyxmvJGl4yz2i+DXgt6rqx4D3AI8De4D7qmojcF97TZKLge3Au4GtwK1Jzmj9fAbYBWxsj62tvhN4uareBXwauHmZ45UkDWnJQZHkTOCngNsAqurPq+pPgW3AvrbZPuDKtrwNuLOqXquqp4DDwGVJLgDOrKoHqqqAO+a0menrLmDLzNGGJGllrFlG2x8G/hj4N0neAzwCfByYqKqjAFV1NMn5bft1wIOz2h9pte+25bn1mTbPtr6mk7wCnAu8OHsgSXYxOCJhYmKCqampoSZy7NixoduM2u5N0yPpZ2Lt8H2t9tx7xmHfjIpzGU/OZWHLCYo1wHuBj1XVwSS/RjvNdALzHQlUp95rc3yhai+wF2Dz5s01OTnZGcb3m5qaYtg2o3bdnq+MpJ/dm6b51KHhduvT10yO5L1PhnHYN6PiXMaTc1nYcq5RHAGOVNXB9vouBsHxfDudRHt+Ydb2F85qvx54rtXXz1M/rk2SNcBZwEvLGLMkaUhLDoqq+l/As0l+tJW2AI8BB4AdrbYDuLstHwC2t28yXcTgovVD7TTVq0kub9cfrp3TZqavq4D723UMSdIKWc6pJ4CPAV9I8mbgW8BHGITP/iQ7gWeAqwGq6tEk+xmEyTRwfVW93vr5KHA7sBa4pz1gcKH880kOMziS2L7M8UqShrSsoKiqrwOb51m15QTb3wjcOE/9YeCSeerfoQWNJGl1+JvZkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUteygyLJGUn+IMl/bK/PSXJvkifb89mztr0hyeEkTyS5Ylb90iSH2rpbkqTV35LkS61+MMmG5Y5XkjScURxRfBx4fNbrPcB9VbURuK+9JsnFwHbg3cBW4NYkZ7Q2nwF2ARvbY2ur7wRerqp3AZ8Gbh7BeCVJQ1hWUCRZD3wI+Oys8jZgX1veB1w5q35nVb1WVU8Bh4HLklwAnFlVD1RVAXfMaTPT113AlpmjDUnSyljuEcWvAv8E+N6s2kRVHQVoz+e3+jrg2VnbHWm1dW15bv24NlU1DbwCnLvMMUuShrBmqQ2T/CzwQlU9kmRyMU3mqVWn3mszdyy7GJy6YmJigqmpqUUM5/87duzY0G1Gbfem6ZH0M7F2+L5We+4947BvRsW5jCfnsrAlBwXwfuDvJPkg8APAmUn+LfB8kguq6mg7rfRC2/4IcOGs9uuB51p9/Tz12W2OJFkDnAW8NHcgVbUX2AuwefPmmpycHGoiU1NTDNtm1K7b85WR9LN70zSfOjTcbn36msmRvPfJMA77ZlScy3hyLgtb8qmnqrqhqtZX1QYGF6nvr6qfBw4AO9pmO4C72/IBYHv7JtNFDC5aP9ROT72a5PJ2/eHaOW1m+rqqvcf3HVFIkk6e5RxRnMhNwP4kO4FngKsBqurRJPuBx4Bp4Pqqer21+ShwO7AWuKc9AG4DPp/kMIMjie0nYbySpI6RBEVVTQFTbflPgC0n2O5G4MZ56g8Dl8xT/w4taCRJq8PfzJYkdRkUkqQug0KS1GVQSJK6DApJUpdBIUnqMigkSV0GhSSpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSeoyKCRJXQaFJKnLoJAkdRkUkqQug0KS1GVQSJK6DApJUteSgyLJhUl+N8njSR5N8vFWPyfJvUmebM9nz2pzQ5LDSZ5IcsWs+qVJDrV1tyRJq78lyZda/WCSDcuYqyRpCZZzRDEN7K6qHwcuB65PcjGwB7ivqjYC97XXtHXbgXcDW4Fbk5zR+voMsAvY2B5bW30n8HJVvQv4NHDzMsYrSVqCJQdFVR2tqq+15VeBx4F1wDZgX9tsH3BlW94G3FlVr1XVU8Bh4LIkFwBnVtUDVVXAHXPazPR1F7Bl5mhDkrQy1oyik3ZK6CeAg8BEVR2FQZgkOb9ttg54cFazI6323bY8tz7T5tnW13SSV4BzgRfnvP8uBkckTExMMDU1NdT4jx07NnSbUdu9aXok/UysHb6v1Z57zzjsm1FxLuPJuSxs2UGR5O3AbwC/WFV/1vmBf74V1an32hxfqNoL7AXYvHlzTU5OLjDq401NTTFsm1G7bs9XRtLP7k3TfOrQcLv16WsmR/LeJ8M47JtRcS7jybksbFnfekryJgYh8YWq+nIrP99OJ9GeX2j1I8CFs5qvB55r9fXz1I9rk2QNcBbw0nLGLEkaznK+9RTgNuDxqvqVWasOADva8g7g7ln17e2bTBcxuGj9UDtN9WqSy1uf185pM9PXVcD97TqGJGmFLOfU0/uBDwOHkny91T4B3ATsT7ITeAa4GqCqHk2yH3iMwTemrq+q11u7jwK3A2uBe9oDBkH0+SSHGRxJbF/GeCVJS7DkoKiq/8r81xAAtpygzY3AjfPUHwYumaf+HVrQSJJWx0i+9aRT24YRXUgf1tM3fWhV3lfScLyFhySpy6CQJHUZFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkroMCklSl0EhSery71HMsVp/m0GSxpVHFJKkLoNCktRlUEiSugwKSVKXQSFJ6jIoJEldBoUkqcugkCR1GRSSpC6DQpLU5S08tGoWc7uU3ZumuW7Et1V5+qYPjbQ/6XTnEYUkqeuUCIokW5M8keRwkj2rPR5JeiMZ+6BIcgbwr4EPABcDP5fk4tUdlSS9cZwK1yguAw5X1bcAktwJbAMeW9VR6ZS1WreS371pmslVeWdpeVJVqz2GriRXAVur6u+31x8G3ldVvzBrm13ArvbyR4Enhnyb84AXRzDccXA6zQVOr/k4l/HkXAb+clW9c74Vp8IRReapHZduVbUX2LvkN0gerqrNS20/Tk6nucDpNR/nMp6cy8LG/hoFcAS4cNbr9cBzqzQWSXrDORWC4veBjUkuSvJmYDtwYJXHJElvGGN/6qmqppP8AvDbwBnA56rq0RG/zZJPW42h02kucHrNx7mMJ+eygLG/mC1JWl2nwqknSdIqMigkSV1vyKBIck6Se5M82Z7PnmebC5P8bpLHkzya5OOrMdYTWei2Jhm4pa3/RpL3rsY4F2MRc7mmzeEbSX4vyXtWY5yLsdjbzST5a0leb78nNJYWM5ckk0m+3j4j/3mlxziMRfw7OyvJf0jyh20+H1mNcS4kyeeSvJDkmydYP/rPflW94R7AvwD2tOU9wM3zbHMB8N62/IPAHwEXr/bY23jOAP478MPAm4E/nDs24IPAPQx+D+Vy4OBqj3sZc/lJ4Oy2/IFTeS6ztrsf+E3gqtUe9zL2yzsY3CHhh9rr81d73Muczydm/i8A3gm8BLx5tcc+z1x+Cngv8M0TrB/5Z/8NeUTB4BYg+9ryPuDKuRtU1dGq+lpbfhV4HFi3UgNcwP+7rUlV/Tkwc1uT2bYBd9TAg8A7klyw0gNdhAXnUlW/V1Uvt5cPMvhdmnG0mP0C8DHgN4AXVnJwQ1rMXP4e8OWqegagqk71+RTwg0kCvJ1BUEyv7DAXVlVfZTC2Exn5Z/+NGhQTVXUUBoEAnN/bOMkG4CeAgyd/aIuyDnh21usjfH+ILWabcTDsOHcy+GlpHC04lyTrgL8L/PoKjmspFrNf/gpwdpKpJI8kuXbFRje8xcznXwE/zuAXeg8BH6+q763M8EZq5J/9sf89iqVK8p+AvzjPqn86ZD9vZ/DT3y9W1Z+NYmwjsOBtTRa5zThY9DiT/C0GQfE3TuqIlm4xc/lV4Jeq6vXBD65jazFzWQNcCmwB1gIPJHmwqv7oZA9uCRYznyuArwN/G/gR4N4k/2WMPveLNfLP/mkbFFX10ydal+T5JBdU1dF2SDbvIXOSNzEIiS9U1ZdP0lCXYjG3NTlVbn2yqHEm+avAZ4EPVNWfrNDYhrWYuWwG7mwhcR7wwSTTVfXvV2SEi7fYf2MvVtW3gW8n+SrwHgbX88bNYubzEeCmGpzoP5zkKeDHgIdWZogjM/LP/hv11NMBYEdb3gHcPXeDdp7yNuDxqvqVFRzbYizmtiYHgGvbNyAuB16ZOd02ZhacS5IfAr4MfHhMf1qdseBcquqiqtpQVRuAu4B/OIYhAYv7N3Y38DeTrEnyVuB9DK7ljaPFzOcZBkdHJJlgcCfqb63oKEdj5J/90/aIYgE3AfuT7GTwj+NqgCR/CfhsVX0QeD/wYeBQkq+3dp+oqt9chfEep05wW5Mk/6Ct/3UG36j5IHAY+N8MfloaO4ucyz8DzgVubT+JT9cY3u1zkXM5JSxmLlX1eJLfAr4BfI/BZ2fer2yutkXum18Gbk9yiMHpm1+qqrG7/XiSLwKTwHlJjgCfBN4EJ++z7y08JEldb9RTT5KkRTIoJEldBoUkqcugkCR1GRSSpC6DQpLUZVBIkrr+L2Q28ZWwP9V6AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_df_scaled[f'logLR:{outstem}.PUM2'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "89910e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(137998, 10)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = target_df_scaled.values\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fbdbde5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataset(data, targets, valid_frac=0.2):\n",
    "    \n",
    "    ind0 = np.where(targets<0)[0]\n",
    "    ind1 = np.where(targets>=0)[0]\n",
    "    \n",
    "    n_neg = int(len(ind0)*valid_frac)\n",
    "    n_pos = int(len(ind1)*valid_frac)\n",
    "\n",
    "    shuf_neg = np.random.permutation(len(ind0))\n",
    "    shuf_pos = np.random.permutation(len(ind1))\n",
    "\n",
    "    X_train = np.concatenate((data[ind1[shuf_pos[n_pos:]]], data[ind0[shuf_neg[n_neg:]]]))\n",
    "    Y_train = np.concatenate((targets[ind1[shuf_pos[n_pos:]]], targets[ind0[shuf_neg[n_neg:]]]))\n",
    "    train = (X_train, Y_train)\n",
    "\n",
    "    X_test = np.concatenate((data[ind1[shuf_pos[:n_pos]]], data[ind0[shuf_neg[:n_neg]]]))\n",
    "    Y_test = np.concatenate((targets[ind1[shuf_pos[:n_pos]]], targets[ind0[shuf_neg[:n_neg]]]))\n",
    "    test = (X_test, Y_test)\n",
    "\n",
    "    return train, test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2731898a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = split_dataset(data, targets, valid_frac=0.2)\n",
    "\n",
    "target_data_type = np.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73f7fdba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1103984, 4, 100), (1103984, 10), (275996, 4, 100), (275996, 10))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0].shape, train[1].shape, test[0].shape, test[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "90b10c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prismnet.model.PrismNet import *\n",
    "class PrismNet_Multitask(nn.Module):\n",
    "    def __init__(self, mode=\"pu\", output_dim=10):\n",
    "        super(PrismNet_Multitask, self).__init__()\n",
    "        self.mode = mode\n",
    "        h_p, h_k = 2, 5 \n",
    "        if mode==\"pu\":\n",
    "            self.n_features = 5\n",
    "        elif mode==\"seq\":\n",
    "            self.n_features = 4\n",
    "            h_p, h_k = 1, 3 \n",
    "        elif mode==\"str\":\n",
    "            self.n_features = 1\n",
    "            h_p, h_k = 0, 1\n",
    "        else:\n",
    "            raise \"mode error\"\n",
    "        \n",
    "        base_channel = 8\n",
    "        self.conv    = Conv2d(1, base_channel, kernel_size=(11, h_k), bn = True, same_padding=True)\n",
    "        self.se      = SEBlock(base_channel)\n",
    "        self.res2d   = ResidualBlock2D(base_channel, kernel_size=(11, h_k), padding=(5, h_p)) \n",
    "        self.res1d   = ResidualBlock1D(base_channel*4) \n",
    "        self.avgpool = nn.AvgPool2d((1,self.n_features))\n",
    "        self.gpool   = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc      = nn.Linear(base_channel*4*8, output_dim)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"[forward]\n",
    "        \n",
    "        Args:\n",
    "            input ([tensor],N,C,W,H): input features\n",
    "        \"\"\"\n",
    "        if self.mode==\"seq\":\n",
    "            input = input[:,:,:,:4]\n",
    "        elif self.mode==\"str\":\n",
    "            input = input[:,:,:,4:]\n",
    "        x = self.conv(input)\n",
    "        x = F.dropout(x, 0.1, training=self.training)\n",
    "        z = self.se(x)\n",
    "        x = self.res2d(x*z)\n",
    "        x = F.dropout(x, 0.5, training=self.training)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], x.shape[1], x.shape[2])\n",
    "        x = self.res1d(x)\n",
    "        x = F.dropout(x, 0.3, training=self.training)\n",
    "        x = self.gpool(x)\n",
    "        x = x.view(x.shape[0], x.shape[1])\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d15e2859",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PrismNet_Multitask(mode = 'seq', output_dim = targets.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "718ce62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fe567b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bfcb7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqicSHAPE_Multitask(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y, is_infer=False, use_structure=True):\n",
    "        \"\"\"data loader\n",
    "        \n",
    "        Args:\n",
    "            data_path ([str]): h5 file path\n",
    "            is_test (bool, optional): testset or not. Defaults to False.\n",
    "        \"\"\"\n",
    "        self.is_infer = is_infer\n",
    "        if is_infer:\n",
    "            \n",
    "            self.dataset = self.__load_infer_data__(data_path, use_structure=use_structure)\n",
    "            print(\"infer data: \", self.__len__(),\" use_structure: \", use_structure)\n",
    "        else:\n",
    "\n",
    "            X = np.array(X).astype(np.float32)\n",
    "            Y = np.array(Y).astype(np.float32)\n",
    "            X = np.expand_dims(X, axis=3).transpose([0, 3, 2, 1]) # N, 1, length, channel\n",
    "            self.dataset = {'inputs': X, 'targets': Y}\n",
    "            \n",
    "\n",
    "    def mask_boundary(self, x,n_nucleotide_to_mask=10):\n",
    "        _, is_data = np.where(x.sum(-1)>0) # if there is padded region\n",
    "        \n",
    "        boundary_end, boundary_start = is_data.max(), is_data.min()\n",
    "        \n",
    "        end_to_mask, start_to_mask = np.random.uniform(low = 0, high = n_nucleotide_to_mask, size = 2)\n",
    "        \n",
    "        \n",
    "        # masking\n",
    "        x[:,boundary_start:boundary_start+int(start_to_mask), :] = 0\n",
    "        x[:,boundary_end-int(end_to_mask):boundary_end, :] = 0\n",
    "        \n",
    "        return x\n",
    "\n",
    "    \n",
    "    def __load_infer_data__(self, data_path, use_structure=True):\n",
    "        from prismnet.utils import datautils\n",
    "        dataset = datautils.load_testset_txt(data_path, use_structure=use_structure, seq_length=101)\n",
    "        return dataset\n",
    "       \n",
    "    \n",
    "    def __prepare_data__(self, data):\n",
    "        inputs    = data['inputs'][:,:,:,:4]\n",
    "        structure = data['inputs'][:,:,:,4:]\n",
    "        structure = np.expand_dims(structure[:,:,:,0], axis=3)\n",
    "        inputs    = np.concatenate([inputs, structure], axis=3)\n",
    "        data['inputs']  = inputs\n",
    "        return data\n",
    "\n",
    "    def __to_sequence__(self, x):\n",
    "        x1 = np.zeros_like(x[0,:,:1])\n",
    "        for i in range(x1.shape[0]):\n",
    "            # import pdb; pdb.set_trace()\n",
    "            x1[i] = np.argmax(x[0,i,:4])\n",
    "            # import pdb; pdb.set_trace()\n",
    "        return x1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        x = self.dataset['inputs'][index]\n",
    "        # x = self.__to_sequence__(x)\n",
    "        y = self.dataset['targets'][index]\n",
    "        \n",
    "        if not self.is_infer:\n",
    "            x = self.mask_boundary(x) # mask at training time\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset['inputs'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "59e3822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set: 1103984\n",
      "Test  set: 275996\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    \n",
    "    \n",
    "    SeqicSHAPE_Multitask(train[0], train[1], is_infer=False, use_structure=False), \n",
    "batch_size=32, shuffle=True,  **kwargs)\n",
    "\n",
    "test_loader  = torch.utils.data.DataLoader(\n",
    "    SeqicSHAPE_Multitask(test[0], test[1], is_infer=False, use_structure=False),\n",
    "batch_size=64*8, shuffle=False, **kwargs)\n",
    "\n",
    "print(\"Train set:\", len(train_loader.dataset)) #X_train (example=91099, ATCGshape=5, length=101)\n",
    "#X_train (example=91099, ATCGshape=5, length=101)\n",
    "#Y_train (example=91099, binary_outcome=1))\n",
    "print(\"Test  set:\", len(test_loader.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6ae85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer):\n",
    "    ''' train for one epoch'''\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (x0, y0) in enumerate(train_loader):\n",
    "        x, y = x0.float().to(device), y0.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        \n",
    "        loss = criterion(output, y)\n",
    "        epoch_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "\n",
    "    return epoch_loss\n",
    "def validate(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    y_all = []\n",
    "    p_all = []\n",
    "    l_all = []\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x0, y0) in enumerate(test_loader):\n",
    "            x, y = x0.float().to(device), y0.to(device).float()\n",
    "            \n",
    "            \n",
    "            output  = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            y_np = output.to(device='cpu', dtype=torch.float32).numpy()\n",
    "            y_all.append(y_np)\n",
    "            \n",
    "\n",
    "    return epoch_loss, y_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "389dabb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "continue to train from 616 epoch, 8.917180802673101\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    metric_df=pd.read_csv(f'../data/ABC_data/{outstem}.maskw.training_curve.csv', index_col = 0)\n",
    "    current_epoch = metric_df['epoch'].max()\n",
    "    model.load_state_dict(torch.load(f'../data/ABC_data/{outstem}.maskw.model.pt'))\n",
    "    # continue training\n",
    "    \n",
    "    best_test_loss = metric_df.loc[metric_df['type']=='test', 'loss'].min()\n",
    "    metric = metric_df.values.tolist()\n",
    "    print(f'continue to train from {current_epoch} epoch, {best_test_loss}')\n",
    "    \n",
    "except Exception as e:\n",
    "    print(e)\n",
    "    current_epoch = 0\n",
    "    best_test_loss = np.inf\n",
    "    metric = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0ca275a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26219/452049904.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#from prismnet.utils import metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0002\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbetas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.999\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight_decay\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mnepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m scheduler = GradualWarmupScheduler(\n\u001b[1;32m      5\u001b[0m     optimizer, multiplier=8, total_epoch=nepoch, after_scheduler=None)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "#from prismnet.utils import metrics\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0002, betas=(0.9, 0.999), weight_decay=1e-6)\n",
    "nepoch = 400\n",
    "scheduler = GradualWarmupScheduler(\n",
    "    optimizer, multiplier=8, total_epoch=nepoch, after_scheduler=None)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(current_epoch, current_epoch + nepoch + 1):\n",
    "    print(f'At epoch {epoch}')\n",
    "    train_loss = train(model, device, train_loader, criterion, optimizer)\n",
    "    metric.append(['train', epoch, train_loss])\n",
    "    \n",
    "    test_loss, y_pred = validate(model, device, test_loader, criterion)\n",
    "    metric.append(['test', epoch, test_loss])\n",
    "\n",
    "    if test_loss < best_test_loss:\n",
    "        filename = f'../data/ABC_data/{outstem}.maskw.model.pt'\n",
    "        torch.save(model.state_dict(), filename)\n",
    "        best_test_loss = test_loss\n",
    "        \n",
    "    metric_df = pd.DataFrame(metric, columns = ['type', 'epoch', 'loss'])\n",
    "    metric_df.to_csv(f'../data/ABC_data/{outstem}.maskw.training_curve.csv')\n",
    "    \n",
    "#     if epoch % 5 == 0:\n",
    "#         metric_df.groupby(by = 'type').plot(x = 'epoch', y = 'loss', subplots = False)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a531187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.load_state_dict(torch.load(f'../data/ABC_data/{outstem}.model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd39f39",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric = pd.DataFrame(metric, columns = ['type', 'epoch', 'loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf891c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0f323ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#metric.to_csv(f'../data/ABC_data/{outstem}.training_curve.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_test, y_test_pred = validate(model, device, test_loader, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e4ce05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = f'../data/ABC_data/{outstem}.model.pt'\n",
    "# torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a875117e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr\n",
    "import matplotlib.pyplot as plt\n",
    "y_pred=np.concatenate(y_test_pred)\n",
    "for rbp_idx, name in zip(range(test[1].shape[1]), target_df.columns):\n",
    "    plt.scatter(test[1][:1000, rbp_idx], y_pred[:1000, rbp_idx])\n",
    "    print(pearsonr(test[1][:1000, rbp_idx],y_pred[:1000, rbp_idx]))\n",
    "    plt.title(name)\n",
    "    plt.show()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
