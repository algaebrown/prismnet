{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b649278e",
   "metadata": {},
   "source": [
    "#follow this to install prismnet\n",
    "https://github.com/kuixu/PrismNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e17a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "from prismnet.model.utils import GradualWarmupScheduler\n",
    "from prismnet.utils import datautils\n",
    "\n",
    "# modified code\n",
    "from model import PrismNet_Multitask\n",
    "from dataloader_unmask import SeqicSHAPE_Multitask\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1218a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "outstem = 'K562_rep6'\n",
    "outstem2 = 'K562_rep6.region_type'\n",
    "rbp = 'RBFOX2'\n",
    "megaoutput = pd.read_csv(f'../data/ABC_data/{outstem}.megaoutputs_masked.tsv', sep = '\\t')\n",
    "seq = pd.read_csv(f'../data/ABC_data/tsv/{outstem}.DDX3.tsv', sep = '\\t', names = ['chrom', 'name', \n",
    "                                                                                 'seq', 'struct', 'label', 'start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f62d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = pd.read_csv(f'../data/variant_clinvar/{outstem}.{rbp}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa595cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=seq['seq'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5126acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = variants.loc[variants['variant_seq'].str.len()<=max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fff7700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also score normal things\n",
    "seq = seq.loc[seq['name'].isin(variants['name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0696d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prismnet.utils import datautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651132bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_wt = datautils.convert_one_hot(seq['seq'], max_length)\n",
    "one_hot_var = datautils.convert_one_hot(variants['variant_seq'], max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54c692bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets: predict binary\n",
    "target_col = megaoutput.columns[(megaoutput.columns.str.startswith('logLR'))&(megaoutput.columns.str.contains(outstem))]\n",
    "target_df = megaoutput.set_index('name').loc[seq['name'],target_col]\n",
    "targets_wt = target_df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "338f2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_var = datautils.convert_one_hot(variants['variant_seq'], max_length)\n",
    "targets_var = variants.merge(target_df, left_on = 'name', right_index = True)[target_df.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89910e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((594, 4, 100), (2778, 4, 100), (594, 10))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_wt.shape, one_hot_var.shape, targets_wt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90b10c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import PrismNet_Multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d15e2859",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_832/210265084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_cuda\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'../data/ABC_data/{outstem}.maskw.model.pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    605\u001b[0m                     \u001b[0mopened_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_position\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    606\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 607\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    608\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    609\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_load\u001b[0;34m(zip_file, map_location, pickle_module, pickle_file, **pickle_load_args)\u001b[0m\n\u001b[1;32m    880\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mUnpicklerWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    881\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 882\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_loaded_sparse_tensors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mpersistent_load\u001b[0;34m(saved_id)\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    856\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 857\u001b[0;31m             \u001b[0mload_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_maybe_decode_ascii\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    858\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload_tensor\u001b[0;34m(data_type, size, key, location)\u001b[0m\n\u001b[1;32m    844\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0mstorage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_storage_from_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m         \u001b[0mloaded_storages\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrestore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mdefault_restore_location\u001b[0;34m(storage, location)\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdefault_restore_location\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_package_registry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_cuda_deserialize\u001b[0;34m(obj, location)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_cuda_deserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlocation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_cuda_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_torch_load_uninitialized\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m             \u001b[0mstorage_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.9/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36mvalidate_cuda_device\u001b[0;34m(location)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         raise RuntimeError('Attempting to deserialize object on a CUDA '\n\u001b[0m\u001b[1;32m    136\u001b[0m                            \u001b[0;34m'device but torch.cuda.is_available() is False. '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                            \u001b[0;34m'If you are running on a CPU-only machine, '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location=torch.device('cpu') to map your storages to the CPU."
     ]
    }
   ],
   "source": [
    "model = PrismNet_Multitask(mode = 'seq', output_dim = targets_wt.shape[1])\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(f'../data/ABC_data/{outstem}.maskw.model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfcb7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader_unmask import SeqicSHAPE_Multitask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e3822a",
   "metadata": {},
   "outputs": [],
   "source": [
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "    \n",
    "    \n",
    "#     SeqicSHAPE_Multitask(train[0], train[1], is_infer=False, use_structure=False), \n",
    "# batch_size=64, shuffle=True,  **kwargs)\n",
    "\n",
    "test_loader  = torch.utils.data.DataLoader(\n",
    "    SeqicSHAPE_Multitask(one_hot_wt, targets_wt, is_infer=False, use_structure=False),\n",
    "batch_size=64*8, shuffle=False, **kwargs)\n",
    "\n",
    "test_loader_var  = torch.utils.data.DataLoader(\n",
    "    SeqicSHAPE_Multitask(one_hot_var, targets_var, is_infer=False, use_structure=False),\n",
    "batch_size=64*8, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "print(\"Test  set:\", len(test_loader.dataset))\n",
    "print(\"Test  set:\", len(test_loader_var.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ae85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer):\n",
    "    ''' train for one epoch'''\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (x0, y0) in enumerate(train_loader):\n",
    "        x, y = x0.float().to(device), y0.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        \n",
    "        loss = criterion(output, y)\n",
    "        epoch_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "\n",
    "    return epoch_loss\n",
    "def validate(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    y_all = []\n",
    "    p_all = []\n",
    "    l_all = []\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x0, y0) in enumerate(test_loader):\n",
    "            x, y = x0.float().to(device), y0.to(device).float()\n",
    "            \n",
    "            \n",
    "            output  = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            y_np = output.to(device='cpu', dtype=torch.float32).numpy()\n",
    "            y_all.append(y_np)\n",
    "            \n",
    "    y_pred=np.concatenate(y_all)\n",
    "    return epoch_loss, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9784c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), weight_decay=1e-6)\n",
    "nepoch = 60\n",
    "scheduler = GradualWarmupScheduler(\n",
    "    optimizer, multiplier=8, total_epoch=nepoch, after_scheduler=None)\n",
    "criterion = torch.nn.MSELoss()\n",
    "batch_size= 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614f8678",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_test, y_pred = validate(model, device, test_loader, criterion)\n",
    "loss_test_var, y_pred_var = validate(model, device, test_loader_var, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1753baa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# \n",
    "# Kui Xu, xukui.cs@gmail.com\n",
    "# 2019-02-25\n",
    "# ref smoothGrad\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad,Variable\n",
    "import numpy as np\n",
    "\n",
    "class SmoothGrad(object):\n",
    "    def __init__(self, model, device='cpu', only_seq=False, train=False, \n",
    "        x_stddev=0.015, t_stddev=0.015, nsamples=20, magnitude=2):\n",
    "        self.model     = model\n",
    "        self.device    = device\n",
    "        self.train     = train\n",
    "        self.only_seq  = only_seq\n",
    "        self.x_stddev  = x_stddev\n",
    "        self.t_stddev  = t_stddev\n",
    "        self.nsamples  = nsamples\n",
    "        self.magnitude = magnitude\n",
    "        self.features  = model\n",
    "        # import pdb; pdb.set_trace()\n",
    "\n",
    "    def get_gradients(self, z, pred_label=None, rbp_idx = 0):\n",
    "        self.model.eval()\n",
    "        self.model.zero_grad()\n",
    "        z = z.to(self.device)\n",
    "        z.requires_grad=True\n",
    "        output = self.model(z)\n",
    "        \n",
    "        output[:,rbp_idx].backward() # now it is a multioutput.... maybe sum is not the right way tho!\n",
    "        return z.grad\n",
    "\n",
    "    def get_smooth_gradients(self, z, y=None, rbp_idx=0):\n",
    "        return self.__call__(z, y, rbp_idx = rbp_idx)\n",
    "        \n",
    "    def __call__(self, z, y=None,rbp_idx = 0):\n",
    "        \"\"\"[summary]\n",
    "        \n",
    "        Args:\n",
    "            z ([type]): [description] X\n",
    "            y ([type]): [description] Y\n",
    "            x_stddev (float, optional): [description]. Defaults to 0.15.\n",
    "            t_stddev (float, optional): [description]. Defaults to 0.15.\n",
    "            nsamples (int, optional):   [description]. Defaults to 20.\n",
    "            magnitude (int, optional):  magnitude:0,1,2; 0: original gradient, 1: absolute value of the gradient,\n",
    "                                        2: square value of the gradient. Defaults to 2.\n",
    "        \n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. for sequece\n",
    "        x = z[:,:,:,:4] # .data.cpu()\n",
    "        x_stddev   = (self.x_stddev * (x.max()-x.min())).to(self.device).item() \n",
    "\n",
    "        total_grad = torch.zeros(z.shape).to(self.device)\n",
    "        x_noise    = torch.zeros(x.shape).to(self.device)\n",
    "        if not self.only_seq:\n",
    "            # 2. for structure  \n",
    "            t = z[:,:,:,4:] #.data.cpu()\n",
    "            t_stddev = (self.t_stddev * (t.max()-t.min())).to(self.device).item() \n",
    "            #t_total_grad = torch.zeros(t.shape)\n",
    "            t_noise = torch.zeros(t.shape).to(self.device)\n",
    "\n",
    "        for i in range(self.nsamples):\n",
    "            x_plus_noise = x + x_noise.zero_().normal_(0, x_stddev)\n",
    "            if self.only_seq:\n",
    "                z_plus_noise = x_plus_noise\n",
    "            else:\n",
    "                t_plus_noise = t + t_noise.zero_().normal_(0, t_stddev)\n",
    "                z_plus_noise = torch.cat((x_plus_noise, t_plus_noise), dim=3)\n",
    "            #print(\"z_plus_noise:\",z_plus_noise.size())\n",
    "            grad = self.get_gradients(z_plus_noise, y, rbp_idx = rbp_idx)\n",
    "            if self.magnitude == 1:\n",
    "                total_grad += torch.abs(grad)\n",
    "            elif self.magnitude == 2:\n",
    "                total_grad += grad * grad\n",
    "            \n",
    "            # total_grad += grad * grad\n",
    "        total_grad /= self.nsamples\n",
    "        return total_grad\n",
    "\n",
    "    def get_batch_gradients(self, X, Y=None, rbp_idx = 0):\n",
    "        if Y is not None:\n",
    "            assert len(X) == len(Y), \"The size of input {} and target {} are not matched.\".format(len(X), len(Y))\n",
    "        g = torch.zeros_like(X)\n",
    "        for i in range(X.shape[0]):\n",
    "            x        = X[i:i+1]\n",
    "            if Y is not None:\n",
    "                y    = Y[i:i+1]\n",
    "            else:\n",
    "                y    = None\n",
    "            g[i:i+1] =  self.get_smooth_gradients(x, y, rbp_idx = rbp_idx)\n",
    "            # g[i:i+1] =  self.get_gradients(x, y)\n",
    "        return g\n",
    "\n",
    "\n",
    "def generate_saliency(model, x, y=None, smooth=False, nsamples=2, stddev=0.15, only_seq=False, \\\n",
    "    train=False):\n",
    "    saliency = SmoothGrad(model, only_seq, train)\n",
    "    x_grad   = saliency.get_smooth_gradients(x, y, nsamples=nsamples, x_stddev=stddev, t_stddev=stddev)\n",
    "    return x_grad\n",
    "\n",
    "\n",
    "\n",
    "class GuidedBackpropReLU(torch.autograd.Function):\n",
    "\n",
    "    def __init__(self, inplace=False):\n",
    "        super(GuidedBackpropReLU, self).__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, input):\n",
    "        pos_mask = (input > 0).type_as(input)\n",
    "        output = torch.addcmul(\n",
    "            torch.zeros(input.size()).type_as(input),\n",
    "            input,\n",
    "            pos_mask)\n",
    "        self.save_for_backward(input, output)\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        input, output = self.saved_tensors\n",
    "\n",
    "        pos_mask_1 = (input > 0).type_as(grad_output)\n",
    "        pos_mask_2 = (grad_output > 0).type_as(grad_output)\n",
    "        grad_input = torch.addcmul(\n",
    "            torch.zeros(input.size()).type_as(input),\n",
    "            torch.addcmul(\n",
    "                torch.zeros(input.size()).type_as(input), grad_output, pos_mask_1),\n",
    "                pos_mask_2)\n",
    "\n",
    "        return grad_input\n",
    "\n",
    "    def __repr__(self):\n",
    "        inplace_str = ', inplace' if self.inplace else ''\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "            + inplace_str + ')'\n",
    "\n",
    "class GuidedBackpropSmoothGrad(SmoothGrad):\n",
    "\n",
    "    def __init__(self, model, device='cpu', only_seq=False, train=False, \n",
    "        x_stddev=0.15, t_stddev=0.15, nsamples=20, magnitude=2):\n",
    "        super(GuidedBackpropSmoothGrad, self).__init__(\n",
    "            model, device, only_seq, train, x_stddev, t_stddev, nsamples, magnitude)\n",
    "        for idx, module in self.features._modules.items():\n",
    "            if module.__class__.__name__ is 'ReLU':\n",
    "                self.features._modules[idx] = GuidedBackpropReLU()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53989681",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_var_df = pd.DataFrame(y_pred_var, index = variants.index, columns = target_df.columns)\n",
    "y_pred_wt_df = pd.DataFrame(y_pred, index = seq['name'], columns = target_df.columns)\n",
    "variants[f'variant_score_{rbp}'] = y_pred_var_df[f'logLR:{outstem}.{rbp}']\n",
    "variants[f'wt_score_{rbp}'] = variants['name'].map(y_pred_wt_df[f'logLR:{outstem}.{rbp}'])\n",
    "variants['delta_score'] = (variants[f'variant_score_{rbp}']-variants[f'wt_score_{rbp}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4bbc2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_selected_var = variants.loc[(variants['delta_score']<-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ee8843",
   "metadata": {},
   "outputs": [],
   "source": [
    "gof_var = variants.loc[(variants['delta_score']>1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7263ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "gof_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1aa4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a much smaller subset\n",
    "one_hot_negvar = datautils.convert_one_hot(neg_selected_var['variant_seq'], max_length)\n",
    "targets_var = neg_selected_var.merge(target_df, left_on = 'name', right_index = True)[target_df.columns].values\n",
    "\n",
    "test_loader_negvar  = torch.utils.data.DataLoader(\n",
    "    SeqicSHAPE_Multitask(one_hot_negvar, targets_var, is_infer=False, use_structure=False),\n",
    "batch_size=64*8, shuffle=False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ab1c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a much smaller subset\n",
    "one_hot_gofvar = datautils.convert_one_hot(gof_var['variant_seq'], max_length)\n",
    "targets_gofvar = gof_var.merge(target_df, left_on = 'name', right_index = True)[target_df.columns].values\n",
    "\n",
    "test_loader_gofvar  = torch.utils.data.DataLoader(\n",
    "    SeqicSHAPE_Multitask(one_hot_gofvar, targets_gofvar, is_infer=False, use_structure=False),\n",
    "batch_size=64*8, shuffle=False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66663fdf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f081f0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_saliency(model, test_loader, rbp):\n",
    "    model.eval()\n",
    "    sgrad = GuidedBackpropSmoothGrad(model, device=device, only_seq = True)\n",
    "    rbp_idx=np.where(target_col.str.contains(rbp))[0][0]\n",
    "    gs = []\n",
    "    for batch_idx, (x0, y0) in enumerate(test_loader):\n",
    "        X, Y = x0.float().to(device), y0.to(device).float()\n",
    "        output = model(X)\n",
    "\n",
    "        guided_saliency = sgrad.get_batch_gradients(X, Y, rbp_idx = rbp_idx)\n",
    "        gs.append(guided_saliency)\n",
    "    gs = torch.cat(gs, axis = 0)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d14ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_wt = get_saliency(model, test_loader, rbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868970a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_var = get_saliency(model, test_loader_negvar, rbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfaad45",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_gofvar = get_saliency(model, test_loader_gofvar, rbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c4d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "saliency_wt.shape, saliency_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a178abf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pybigwig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2ffa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyBigWig\n",
    "import numpy as np\n",
    "\n",
    "class strand_specific_wig:\n",
    "    def __init__(self, plus, minus):\n",
    "        self.plus = pyBigWig.open(plus)\n",
    "        self.minus = pyBigWig.open(minus)\n",
    "        \n",
    "    def fetch(self, chrom = None, start= None, end=None, strand= None, interval = None):\n",
    "        ''' return icSHAPE reacitivity for a bedtool interval or chrom, start, end, strand'''\n",
    "        if interval:\n",
    "            start = interval.start\n",
    "            end = interval.end\n",
    "            strand = interval.strand\n",
    "            chrom = interval.chrom\n",
    "        if strand == '-':\n",
    "            icshape_data = self.minus\n",
    "        else:\n",
    "            icshape_data = self.plus\n",
    "        values = icshape_data.values(chrom, start, end)\n",
    "        if strand == '-':\n",
    "            values = values[::-1]\n",
    "        return np.nan_to_num(np.array(values), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88337251",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbp_wig_cits = strand_specific_wig(f'../data/CITS/{rbp}.pos.bw',\n",
    "                                 f'../data/CITS/{rbp}.neg.bw'\n",
    "                                 )\n",
    "rbp_wig_cov = strand_specific_wig(f'../data/COV/{rbp}.pos.bw',\n",
    "                             f'../data/COV/{rbp}.neg.bw'\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308bcf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install logomaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0af877f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import logomaker\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_saliency(gs, index, subset_seq_df, one_hot):\n",
    "    index2seq = 'ACGU'\n",
    "    \n",
    "\n",
    "    # find coverage\n",
    "    window_name = subset_seq_df.iloc[index]['name']\n",
    "    print(window_name)\n",
    "    row = megaoutput.loc[megaoutput['name']==window_name].iloc[0]\n",
    "    wig_values = rbp_wig_cov.fetch(row['chrom'], row['start'], row['end'], row['strand'])\n",
    "    wig_values_cits = rbp_wig_cits.fetch(row['chrom'], row['start'], row['end'], row['strand'])\n",
    "\n",
    "    seq_values = one_hot[index,:,:] # [1,4,100]\n",
    "    gradient_values = gs[index,0,:,:].cpu().numpy() # [1,1,100,4]\n",
    "    saliency_values = gradient_values * seq_values.T # 4*100\n",
    "    saliency_df = pd.DataFrame(saliency_values.T)\n",
    "    saliency_df.index = list(index2seq)\n",
    "\n",
    "    saliency_df = saliency_df.loc[:, seq_values.sum(axis = 0)!=0].T\n",
    "    saliency_df.index = np.arange(saliency_df.shape[0])\n",
    "\n",
    "    f, ax = plt.subplots(2,1, sharex = True, figsize = (12,4))\n",
    "    logomaker.Logo(saliency_df, # only plot places with sequence\n",
    "                              shade_below=.5,\n",
    "                              fade_below=.5,\n",
    "                              font_name='Arial Rounded MT Bold', \n",
    "                  ax = ax[0])\n",
    "\n",
    "\n",
    "    ax[0].set_ylabel('saliency')\n",
    "    ax[1].bar(np.arange(len(wig_values)), wig_values, color = 'lightgrey')\n",
    "    ax[1].set_ylabel('coverage')\n",
    "#     ax[2].bar(np.arange(len(wig_values_cits)), wig_values_cits, color = 'lightgrey')\n",
    "#     ax[2].plot(gaussian_filter1d(wig_values_cits, 3), color = 'tomato', label = 'smoothed CITS')\n",
    "#     ax[2].set_ylabel('#CITS')\n",
    "\n",
    "    ax[0].set_title(row['chrom'] + ':'+str(row['start'])+'-'+str(row['end'])+':'+row['strand'])\n",
    "    sns.despine()\n",
    "    \n",
    "    if 'POS' in subset_seq_df.iloc[index]:\n",
    "        print(subset_seq_df.iloc[index]['POS']-row['start'])\n",
    "        if row['strand']=='+':\n",
    "            index = subset_seq_df.iloc[index]['POS']-row['start']\n",
    "            \n",
    "        else:\n",
    "            index = row['end']-subset_seq_df.iloc[index]['POS']\n",
    "        ax[0].text(index-0.5, max(saliency_values[index,:]), '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed25f6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_selected_var['rbp_idx'] = np.arange(neg_selected_var.shape[0])\n",
    "seq['rbp_idx'] = np.arange(seq.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d82ed1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gof_var['rbp_idx'] = np.arange(gof_var.shape[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebacb97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_selected_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "024e58db",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_selected_var.loc[(neg_selected_var['delta_score']<-1)&(neg_selected_var['INFO/CLNSIG']=='Uncertain_significance'), ['CHROM', 'POS', 'REF', 'ALT', \n",
    "                                                          'gene_name', 'feature_types',\n",
    "                                                         'INFO/CLNDN',\n",
    "                                                         'delta_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c126cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_selected_var.loc[neg_selected_var['delta_score']<-1,'gene_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e63cc41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_selected_var.loc[(neg_selected_var['delta_score']<-1)&(neg_selected_var['gene_name']=='POLD1'),\n",
    "                    ['CHROM', 'POS', 'REF', 'ALT', \n",
    "                                                          'gene_name', 'feature_types',\n",
    "                                                         'INFO/CLNDN',\n",
    "                                                         'delta_score']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f5ebd0",
   "metadata": {},
   "source": [
    "# gof_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820c78f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_saliency(gof_var, 303, neg_selected_var, one_hot_negvar)\n",
    "#plt.savefig('DGCR8_rs1025053135.var.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1061f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"pdf.fonttype\"] = 42\n",
    "plot_saliency(saliency_var, 721, neg_selected_var, one_hot_negvar)\n",
    "plt.savefig('POLD1.var.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "696efbc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "chr5    +       90679548        90679629"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5490e3a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import rcParams\n",
    "\n",
    "rcParams[\"pdf.fonttype\"] = 42\n",
    "plot_saliency(saliency_wt, seq.loc[seq['name']==neg_selected_var.iloc[721]['name'], 'rbp_idx'].values[0], seq, one_hot_wt)\n",
    "plt.savefig('POLD1.wt.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1dfd7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_many_saliency(gs, indices, subset_seq_df, one_hot):\n",
    "    index2seq = 'ACGU'\n",
    "    \n",
    "\n",
    "    # find coverage\n",
    "    all_wig_value = []\n",
    "    all_saliency_values = []\n",
    "    window_names = subset_seq_df.loc[subset_seq_df['rbp_idx'].isin(indices), 'name']\n",
    "    sub = megaoutput.loc[megaoutput['name'].isin(window_names)].iloc[0]\n",
    "    for index in indices:\n",
    "        window_name = subset_seq_df.iloc[index]['name']\n",
    "        row = megaoutput.loc[megaoutput['name']==window_name].iloc[0]\n",
    "        wig_values = rbp_wig_cov.fetch(row['chrom'], row['start'], row['end'], row['strand'])\n",
    "        wig_values_cits = rbp_wig_cits.fetch(row['chrom'], row['start'], row['end'], row['strand'])\n",
    "\n",
    "        seq_values = one_hot[index,:,:] # [1,4,100]\n",
    "        gradient_values = gs[index,0,:,:].cpu().numpy() # [1,1,100,4]\n",
    "        saliency_values = gradient_values * seq_values.T # 4*100\n",
    "        saliency_df = pd.DataFrame(saliency_values.T)\n",
    "        saliency_df.index = list(index2seq)\n",
    "\n",
    "        saliency_df = saliency_df.loc[:, seq_values.sum(axis = 0)!=0].T\n",
    "        saliency_df.index = np.arange(saliency_df.shape[0])\n",
    "        \n",
    "        all_wig_value.append(wig_values)\n",
    "        all_saliency_values.append(saliency_df)\n",
    "        \n",
    "    \n",
    "    all_wig_value = np.concatenate(all_wig_value)\n",
    "    all_saliency_df = pd.concat(all_saliency_values, axis = 0, ignore_index = True)\n",
    "    print(all_saliency_df)\n",
    "    \n",
    "    f, ax = plt.subplots(2,1, sharex = True, figsize = (60,4))\n",
    "    logomaker.Logo(all_saliency_df, # only plot places with sequence\n",
    "                              shade_below=.5,\n",
    "                              fade_below=.5,\n",
    "                              font_name='Arial Rounded MT Bold', \n",
    "                  ax = ax[0])\n",
    "\n",
    "\n",
    "    ax[0].set_ylabel('saliency')\n",
    "    ax[1].bar(np.arange(len(all_wig_value)), all_wig_value, color = 'lightgrey')\n",
    "    ax[1].set_ylabel('coverage')\n",
    "    \n",
    "\n",
    "    ax[0].set_title(row['chrom'] + ':'+str(sub['start'].min())+'-'+str(sub['end'].max())+':'+row['strand'])\n",
    "    print(row['chrom'] + ':'+str(sub['start'].min())+'-'+str(sub['end'].max())+':'+row['strand'])\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c73d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_many_saliency(saliency_wt, [8,9,10,11,12,13,14], seq, one_hot_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e167f318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
