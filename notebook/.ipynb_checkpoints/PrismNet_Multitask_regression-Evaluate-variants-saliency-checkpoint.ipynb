{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b649278e",
   "metadata": {},
   "source": [
    "#follow this to install prismnet\n",
    "https://github.com/kuixu/PrismNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e17a279",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os, random\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "\n",
    "\n",
    "\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "\n",
    "import prismnet.model as arch\n",
    "from prismnet import train, validate, inference, log_print, compute_saliency, compute_saliency_img, compute_high_attention_region\n",
    "#compute_high_attention_region\n",
    "\n",
    "# from prismnet.engine.train_loop import \n",
    "from prismnet.model.utils import GradualWarmupScheduler\n",
    "from prismnet.loader import SeqicSHAPE\n",
    "from prismnet.utils import datautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1218a44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "outstem = 'K562_rep6'\n",
    "outstem2 = 'K562_rep6.region_type'\n",
    "rbp = 'SF3B4'\n",
    "megaoutput = pd.read_csv(f'../data/ABC_data/{outstem}.megaoutputs_masked.tsv', sep = '\\t')\n",
    "seq = pd.read_csv(f'../data/ABC_data/tsv/{outstem}.DDX3.tsv', sep = '\\t', names = ['chrom', 'name', \n",
    "                                                                                 'seq', 'struct', 'label', 'start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f62d431",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = pd.read_csv(f'../data/variants/{outstem}.{rbp}.chr22.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa595cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length=seq['seq'].str.len().max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5126acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = variants.loc[variants['variant_seq'].str.len()<=max_length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1fff7700",
   "metadata": {},
   "outputs": [],
   "source": [
    "# also score normal things\n",
    "seq = seq.loc[seq['name'].isin(variants['name'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b0696d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prismnet.utils import datautils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "651132bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_wt = datautils.convert_one_hot(seq['seq'], max_length)\n",
    "one_hot_var = datautils.convert_one_hot(variants['variant_seq'], max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54c692bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# targets: predict binary\n",
    "target_col = megaoutput.columns[(megaoutput.columns.str.startswith('logLR'))&(megaoutput.columns.str.contains(outstem))]\n",
    "target_df = megaoutput.set_index('name').loc[seq['name'],target_col]\n",
    "targets_wt = target_df.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "338f2822",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_var = datautils.convert_one_hot(variants['variant_seq'], max_length)\n",
    "targets_var = variants.merge(target_df, left_on = 'name', right_index = True)[target_df.columns].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89910e8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((246, 4, 100), (4464, 4, 100), (246, 10))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_wt.shape, one_hot_var.shape, targets_wt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "90b10c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prismnet.model.PrismNet import *\n",
    "class PrismNet_Multitask(nn.Module):\n",
    "    def __init__(self, mode=\"pu\", output_dim=10):\n",
    "        super(PrismNet_Multitask, self).__init__()\n",
    "        self.mode = mode\n",
    "        h_p, h_k = 2, 5 \n",
    "        if mode==\"pu\":\n",
    "            self.n_features = 5\n",
    "        elif mode==\"seq\":\n",
    "            self.n_features = 4\n",
    "            h_p, h_k = 1, 3 \n",
    "        elif mode==\"str\":\n",
    "            self.n_features = 1\n",
    "            h_p, h_k = 0, 1\n",
    "        else:\n",
    "            raise \"mode error\"\n",
    "        \n",
    "        base_channel = 8\n",
    "        self.conv    = Conv2d(1, base_channel, kernel_size=(11, h_k), bn = True, same_padding=True)\n",
    "        self.se      = SEBlock(base_channel)\n",
    "        self.res2d   = ResidualBlock2D(base_channel, kernel_size=(11, h_k), padding=(5, h_p)) \n",
    "        self.res1d   = ResidualBlock1D(base_channel*4) \n",
    "        self.avgpool = nn.AvgPool2d((1,self.n_features))\n",
    "        self.gpool   = nn.AdaptiveAvgPool1d(1)\n",
    "        self.fc      = nn.Linear(base_channel*4*8, output_dim)\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Conv1d):\n",
    "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "                if m.bias is not None:\n",
    "                    nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                nn.init.normal_(m.weight, 0, 0.01)\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "    \n",
    "    def forward(self, input):\n",
    "        \"\"\"[forward]\n",
    "        \n",
    "        Args:\n",
    "            input ([tensor],N,C,W,H): input features\n",
    "        \"\"\"\n",
    "        if self.mode==\"seq\":\n",
    "            input = input[:,:,:,:4]\n",
    "        elif self.mode==\"str\":\n",
    "            input = input[:,:,:,4:]\n",
    "        x = self.conv(input)\n",
    "        x = F.dropout(x, 0.1, training=self.training)\n",
    "        z = self.se(x)\n",
    "        x = self.res2d(x*z)\n",
    "        x = F.dropout(x, 0.5, training=self.training)\n",
    "        x = self.avgpool(x)\n",
    "        x = x.view(x.shape[0], x.shape[1], x.shape[2])\n",
    "        x = self.res1d(x)\n",
    "        x = F.dropout(x, 0.3, training=self.training)\n",
    "        x = self.gpool(x)\n",
    "        x = x.view(x.shape[0], x.shape[1])\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d15e2859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = PrismNet_Multitask(mode = 'seq', output_dim = targets_wt.shape[1])\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(f'../data/ABC_data/{outstem}.mask.model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bfcb7fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqicSHAPE_Multitask(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, Y, is_infer=False, use_structure=True):\n",
    "        \"\"\"data loader\n",
    "        \n",
    "        Args:\n",
    "            data_path ([str]): h5 file path\n",
    "            is_test (bool, optional): testset or not. Defaults to False.\n",
    "        \"\"\"\n",
    "        if is_infer:\n",
    "            self.dataset = self.__load_infer_data__(data_path, use_structure=use_structure)\n",
    "            print(\"infer data: \", self.__len__(),\" use_structure: \", use_structure)\n",
    "        else:\n",
    "#             dataset = h5py.File(data_path, 'r')\n",
    "#             X_train = np.array(dataset['X_train']).astype(np.float32)\n",
    "#             Y_train = np.array(dataset['Y_train']).astype(np.int32)\n",
    "#             X_test  = np.array(dataset['X_test']).astype(np.float32)\n",
    "#             Y_test  = np.array(dataset['Y_test']).astype(np.int32)\n",
    "            X = np.array(X).astype(np.float32)\n",
    "            Y = np.array(Y).astype(np.float32)\n",
    "#             if len(Y_train.shape) == 1:\n",
    "#                 Y_train = np.expand_dims(Y_train, axis=1)\n",
    "#                 Y_test  = np.expand_dims(Y_test, axis=1)\n",
    "            X = np.expand_dims(X, axis=3).transpose([0, 3, 2, 1]) # N, 1, length, channel\n",
    "            \n",
    "\n",
    "            \n",
    "\n",
    "#             labels, nums = np.unique(Y_train,return_counts=True)\n",
    "#             print(\"train:\", labels, nums)\n",
    "#             labels, nums = np.unique(Y_test,return_counts=True)\n",
    "#             print(\"test:\", labels, nums)\n",
    "\n",
    "#             train = self.__prepare_data__(train)\n",
    "#             test  = self.__prepare_data__(test)\n",
    "\n",
    "            \n",
    "            self.dataset = {'inputs': X, 'targets': Y}\n",
    "            \n",
    "\n",
    "        \n",
    "\n",
    "    def __load_infer_data__(self, data_path, use_structure=True):\n",
    "        from prismnet.utils import datautils\n",
    "        dataset = datautils.load_testset_txt(data_path, use_structure=use_structure, seq_length=101)\n",
    "        return dataset\n",
    "       \n",
    "    \n",
    "    def __prepare_data__(self, data):\n",
    "        inputs    = data['inputs'][:,:,:,:4]\n",
    "        structure = data['inputs'][:,:,:,4:]\n",
    "        structure = np.expand_dims(structure[:,:,:,0], axis=3)\n",
    "        inputs    = np.concatenate([inputs, structure], axis=3)\n",
    "        data['inputs']  = inputs\n",
    "        return data\n",
    "\n",
    "    def __to_sequence__(self, x):\n",
    "        x1 = np.zeros_like(x[0,:,:1])\n",
    "        for i in range(x1.shape[0]):\n",
    "            # import pdb; pdb.set_trace()\n",
    "            x1[i] = np.argmax(x[0,i,:4])\n",
    "            # import pdb; pdb.set_trace()\n",
    "        return x1\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            index (int): Index\n",
    "\n",
    "        Returns:\n",
    "            tuple: (image, target) where target is index of the target class.\n",
    "        \"\"\"\n",
    "        x = self.dataset['inputs'][index]\n",
    "        # x = self.__to_sequence__(x)\n",
    "        y = self.dataset['targets'][index]\n",
    "        return x, y\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset['inputs'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "59e3822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test  set: 246\n",
      "Test  set: 4464\n"
     ]
    }
   ],
   "source": [
    "kwargs = {'num_workers': 2, 'pin_memory': True} if use_cuda else {}\n",
    "# train_loader = torch.utils.data.DataLoader(\n",
    "    \n",
    "    \n",
    "#     SeqicSHAPE_Multitask(train[0], train[1], is_infer=False, use_structure=False), \n",
    "# batch_size=64, shuffle=True,  **kwargs)\n",
    "\n",
    "test_loader  = torch.utils.data.DataLoader(\n",
    "    SeqicSHAPE_Multitask(one_hot_wt, targets_wt, is_infer=False, use_structure=False),\n",
    "batch_size=64*8, shuffle=False, **kwargs)\n",
    "\n",
    "test_loader_var  = torch.utils.data.DataLoader(\n",
    "    SeqicSHAPE_Multitask(one_hot_var, targets_var, is_infer=False, use_structure=False),\n",
    "batch_size=64*8, shuffle=False, **kwargs)\n",
    "\n",
    "\n",
    "print(\"Test  set:\", len(test_loader.dataset))\n",
    "print(\"Test  set:\", len(test_loader_var.dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e6ae85cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, criterion, optimizer):\n",
    "    ''' train for one epoch'''\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "    for batch_idx, (x0, y0) in enumerate(train_loader):\n",
    "        x, y = x0.float().to(device), y0.to(device).float()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model(x)\n",
    "        \n",
    "        loss = criterion(output, y)\n",
    "        epoch_loss+=loss.item()\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 5)\n",
    "        optimizer.step()\n",
    "\n",
    "    return epoch_loss\n",
    "def validate(model, device, test_loader, criterion):\n",
    "    model.eval()\n",
    "    y_all = []\n",
    "    p_all = []\n",
    "    l_all = []\n",
    "    epoch_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (x0, y0) in enumerate(test_loader):\n",
    "            x, y = x0.float().to(device), y0.to(device).float()\n",
    "            \n",
    "            \n",
    "            output  = model(x)\n",
    "            loss = criterion(output, y)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            y_np = output.to(device='cpu', dtype=torch.float32).numpy()\n",
    "            y_all.append(y_np)\n",
    "            \n",
    "    y_pred=np.concatenate(y_all)\n",
    "    return epoch_loss, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9784c9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001, betas=(0.9, 0.999), weight_decay=1e-6)\n",
    "nepoch = 60\n",
    "scheduler = GradualWarmupScheduler(\n",
    "    optimizer, multiplier=8, total_epoch=nepoch, after_scheduler=None)\n",
    "criterion = torch.nn.MSELoss()\n",
    "batch_size= 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "614f8678",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    }
   ],
   "source": [
    "loss_test, y_pred = validate(model, device, test_loader, criterion)\n",
    "loss_test_var, y_pred_var = validate(model, device, test_loader_var, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4171641e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:150: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "<>:150: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "/tmp/ipykernel_203/2063606002.py:150: SyntaxWarning: \"is\" with a literal. Did you mean \"==\"?\n",
      "  if module.__class__.__name__ is 'ReLU':\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# \n",
    "# Kui Xu, xukui.cs@gmail.com\n",
    "# 2019-02-25\n",
    "# ref smoothGrad\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import grad,Variable\n",
    "import numpy as np\n",
    "\n",
    "class SmoothGrad(object):\n",
    "    def __init__(self, model, device='cpu', only_seq=False, train=False, \n",
    "        x_stddev=0.015, t_stddev=0.015, nsamples=20, magnitude=2):\n",
    "        self.model     = model\n",
    "        self.device    = device\n",
    "        self.train     = train\n",
    "        self.only_seq  = only_seq\n",
    "        self.x_stddev  = x_stddev\n",
    "        self.t_stddev  = t_stddev\n",
    "        self.nsamples  = nsamples\n",
    "        self.magnitude = magnitude\n",
    "        self.features  = model\n",
    "        # import pdb; pdb.set_trace()\n",
    "\n",
    "    def get_gradients(self, z, pred_label=None, rbp_idx = 0):\n",
    "        self.model.eval()\n",
    "        self.model.zero_grad()\n",
    "        z = z.to(self.device)\n",
    "        z.requires_grad=True\n",
    "        output = self.model(z)\n",
    "        \n",
    "        output[:,rbp_idx].backward() # now it is a multioutput.... maybe sum is not the right way tho!\n",
    "        return z.grad\n",
    "\n",
    "    def get_smooth_gradients(self, z, y=None, rbp_idx=0):\n",
    "        return self.__call__(z, y, rbp_idx = rbp_idx)\n",
    "        \n",
    "    def __call__(self, z, y=None,rbp_idx = 0):\n",
    "        \"\"\"[summary]\n",
    "        \n",
    "        Args:\n",
    "            z ([type]): [description] X\n",
    "            y ([type]): [description] Y\n",
    "            x_stddev (float, optional): [description]. Defaults to 0.15.\n",
    "            t_stddev (float, optional): [description]. Defaults to 0.15.\n",
    "            nsamples (int, optional):   [description]. Defaults to 20.\n",
    "            magnitude (int, optional):  magnitude:0,1,2; 0: original gradient, 1: absolute value of the gradient,\n",
    "                                        2: square value of the gradient. Defaults to 2.\n",
    "        \n",
    "        Returns:\n",
    "            [type]: [description]\n",
    "        \"\"\"\n",
    "\n",
    "        # 1. for sequece\n",
    "        x = z[:,:,:,:4] # .data.cpu()\n",
    "        x_stddev   = (self.x_stddev * (x.max()-x.min())).to(self.device).item() \n",
    "\n",
    "        total_grad = torch.zeros(z.shape).to(self.device)\n",
    "        x_noise    = torch.zeros(x.shape).to(self.device)\n",
    "        if not self.only_seq:\n",
    "            # 2. for structure  \n",
    "            t = z[:,:,:,4:] #.data.cpu()\n",
    "            t_stddev = (self.t_stddev * (t.max()-t.min())).to(self.device).item() \n",
    "            #t_total_grad = torch.zeros(t.shape)\n",
    "            t_noise = torch.zeros(t.shape).to(self.device)\n",
    "\n",
    "        for i in range(self.nsamples):\n",
    "            x_plus_noise = x + x_noise.zero_().normal_(0, x_stddev)\n",
    "            if self.only_seq:\n",
    "                z_plus_noise = x_plus_noise\n",
    "            else:\n",
    "                t_plus_noise = t + t_noise.zero_().normal_(0, t_stddev)\n",
    "                z_plus_noise = torch.cat((x_plus_noise, t_plus_noise), dim=3)\n",
    "            #print(\"z_plus_noise:\",z_plus_noise.size())\n",
    "            grad = self.get_gradients(z_plus_noise, y, rbp_idx = rbp_idx)\n",
    "            if self.magnitude == 1:\n",
    "                total_grad += torch.abs(grad)\n",
    "            elif self.magnitude == 2:\n",
    "                total_grad += grad * grad\n",
    "            \n",
    "            # total_grad += grad * grad\n",
    "        total_grad /= self.nsamples\n",
    "        return total_grad\n",
    "\n",
    "    def get_batch_gradients(self, X, Y=None, rbp_idx = 0):\n",
    "        if Y is not None:\n",
    "            assert len(X) == len(Y), \"The size of input {} and target {} are not matched.\".format(len(X), len(Y))\n",
    "        g = torch.zeros_like(X)\n",
    "        for i in range(X.shape[0]):\n",
    "            x        = X[i:i+1]\n",
    "            if Y is not None:\n",
    "                y    = Y[i:i+1]\n",
    "            else:\n",
    "                y    = None\n",
    "            g[i:i+1] =  self.get_smooth_gradients(x, y, rbp_idx = rbp_idx)\n",
    "            # g[i:i+1] =  self.get_gradients(x, y)\n",
    "        return g\n",
    "\n",
    "\n",
    "def generate_saliency(model, x, y=None, smooth=False, nsamples=2, stddev=0.15, only_seq=False, \\\n",
    "    train=False):\n",
    "    saliency = SmoothGrad(model, only_seq, train)\n",
    "    x_grad   = saliency.get_smooth_gradients(x, y, nsamples=nsamples, x_stddev=stddev, t_stddev=stddev)\n",
    "    return x_grad\n",
    "\n",
    "\n",
    "\n",
    "class GuidedBackpropReLU(torch.autograd.Function):\n",
    "\n",
    "    def __init__(self, inplace=False):\n",
    "        super(GuidedBackpropReLU, self).__init__()\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, input):\n",
    "        pos_mask = (input > 0).type_as(input)\n",
    "        output = torch.addcmul(\n",
    "            torch.zeros(input.size()).type_as(input),\n",
    "            input,\n",
    "            pos_mask)\n",
    "        self.save_for_backward(input, output)\n",
    "        return output\n",
    "\n",
    "    def backward(self, grad_output):\n",
    "        input, output = self.saved_tensors\n",
    "\n",
    "        pos_mask_1 = (input > 0).type_as(grad_output)\n",
    "        pos_mask_2 = (grad_output > 0).type_as(grad_output)\n",
    "        grad_input = torch.addcmul(\n",
    "            torch.zeros(input.size()).type_as(input),\n",
    "            torch.addcmul(\n",
    "                torch.zeros(input.size()).type_as(input), grad_output, pos_mask_1),\n",
    "                pos_mask_2)\n",
    "\n",
    "        return grad_input\n",
    "\n",
    "    def __repr__(self):\n",
    "        inplace_str = ', inplace' if self.inplace else ''\n",
    "        return self.__class__.__name__ + ' (' \\\n",
    "            + inplace_str + ')'\n",
    "\n",
    "class GuidedBackpropSmoothGrad(SmoothGrad):\n",
    "\n",
    "    def __init__(self, model, device='cpu', only_seq=False, train=False, \n",
    "        x_stddev=0.15, t_stddev=0.15, nsamples=20, magnitude=2):\n",
    "        super(GuidedBackpropSmoothGrad, self).__init__(\n",
    "            model, device, only_seq, train, x_stddev, t_stddev, nsamples, magnitude)\n",
    "        for idx, module in self.features._modules.items():\n",
    "            if module.__class__.__name__ is 'ReLU':\n",
    "                self.features._modules[idx] = GuidedBackpropReLU()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d75201e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_var_df = pd.DataFrame(y_pred_var, index = variants.index, columns = target_df.columns)\n",
    "y_pred_wt_df = pd.DataFrame(y_pred, index = seq['name'], columns = target_df.columns)\n",
    "variants[f'variant_score_{rbp}'] = y_pred_var_df[f'logLR:{outstem}.{rbp}']\n",
    "variants[f'wt_score_{rbp}'] = variants['name'].map(y_pred_wt_df[f'logLR:{outstem}.{rbp}'])\n",
    "variants['delta_score'] = (variants[f'variant_score_{rbp}']-variants[f'wt_score_{rbp}'])\n",
    "variants['MAF']=(variants['INFO/AC']/variants['INFO/AN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0d0215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_selected_var = variants.loc[(variants['MAF']<0.001)&(variants['delta_score']<-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "614b65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a much smaller subset\n",
    "one_hot_negvar = datautils.convert_one_hot(neg_selected_var['variant_seq'], max_length)\n",
    "targets_var = neg_selected_var.merge(target_df, left_on = 'name', right_index = True)[target_df.columns].values\n",
    "\n",
    "test_loader_negvar  = torch.utils.data.DataLoader(\n",
    "    SeqicSHAPE_Multitask(one_hot_negvar, targets_var, is_infer=False, use_structure=False),\n",
    "batch_size=64*8, shuffle=False, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb248566",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_saliency(model, test_loader, rbp):\n",
    "    model.eval()\n",
    "    sgrad = GuidedBackpropSmoothGrad(model, device=device, only_seq = True)\n",
    "    rbp_idx=np.where(target_col.str.contains(rbp))[0][0]\n",
    "    gs = []\n",
    "    for batch_idx, (x0, y0) in enumerate(test_loader):\n",
    "        X, Y = x0.float().to(device), y0.to(device).float()\n",
    "        output = model(X)\n",
    "\n",
    "        guided_saliency = sgrad.get_batch_gradients(X, Y, rbp_idx = rbp_idx)\n",
    "        gs.append(guided_saliency)\n",
    "    gs = torch.cat(gs, axis = 0)\n",
    "    return gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8937af0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    }
   ],
   "source": [
    "saliency_wt = get_saliency(model, test_loader, rbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4df613d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n",
      "[W pthreadpool-cpp.cc:90] Warning: Leaking Caffe2 thread-pool after fork. (function pthreadpool)\n"
     ]
    }
   ],
   "source": [
    "saliency_var = get_saliency(model, test_loader_negvar, rbp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "cc4f2c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([246, 1, 100, 4]), torch.Size([121, 1, 100, 4]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saliency_wt.shape, saliency_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "42c32cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pybigwig\n",
      "  Using cached pyBigWig-0.3.22-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (217 kB)\n",
      "Installing collected packages: pybigwig\n",
      "Successfully installed pybigwig-0.3.22\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install pybigwig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3c344c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyBigWig\n",
    "import numpy as np\n",
    "\n",
    "class strand_specific_wig:\n",
    "    def __init__(self, plus, minus):\n",
    "        self.plus = pyBigWig.open(plus)\n",
    "        self.minus = pyBigWig.open(minus)\n",
    "        \n",
    "    def fetch(self, chrom = None, start= None, end=None, strand= None, interval = None):\n",
    "        ''' return icSHAPE reacitivity for a bedtool interval or chrom, start, end, strand'''\n",
    "        if interval:\n",
    "            start = interval.start\n",
    "            end = interval.end\n",
    "            strand = interval.strand\n",
    "            chrom = interval.chrom\n",
    "        if strand == '-':\n",
    "            icshape_data = self.minus\n",
    "        else:\n",
    "            icshape_data = self.plus\n",
    "        values = icshape_data.values(chrom, start, end)\n",
    "        if strand == '-':\n",
    "            values = values[::-1]\n",
    "        return np.nan_to_num(np.array(values), 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "70b24993",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbp_wig_cits = strand_specific_wig(f'../data/CITS/{rbp}.pos.bw',\n",
    "                                 f'../data/CITS/{rbp}.neg.bw'\n",
    "                                 )\n",
    "rbp_wig_cov = strand_specific_wig(f'../data/COV/{rbp}.pos.bw',\n",
    "                             f'../data/COV/{rbp}.neg.bw'\n",
    "                             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9dcf7d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting logomaker\n",
      "  Using cached logomaker-0.8-py2.py3-none-any.whl (11.8 MB)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/lib/python3.9/site-packages (from logomaker) (3.4.2)\n",
      "Requirement already satisfied: numpy in /home/hsher/.local/lib/python3.9/site-packages (from logomaker) (1.22.2)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.9/site-packages (from logomaker) (1.3.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->logomaker) (1.3.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /opt/conda/lib/python3.9/site-packages (from matplotlib->logomaker) (6.2.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.9/site-packages (from matplotlib->logomaker) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.9/site-packages (from matplotlib->logomaker) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.9/site-packages (from matplotlib->logomaker) (0.10.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /opt/conda/lib/python3.9/site-packages (from pandas->logomaker) (2021.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.9/site-packages (from cycler>=0.10->matplotlib->logomaker) (1.15.0)\n",
      "Installing collected packages: logomaker\n",
      "Successfully installed logomaker-0.8\n",
      "\u001b[33mWARNING: You are using pip version 22.0.3; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install logomaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9610d9ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import logomaker\n",
    "from scipy.ndimage import gaussian_filter1d\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_saliency(gs, index, subset_seq_df, one_hot):\n",
    "    index2seq = 'ACGU'\n",
    "    \n",
    "\n",
    "    # find coverage\n",
    "    window_name = subset_seq_df.iloc[index]['name']\n",
    "    print(window_name)\n",
    "    row = megaoutput.loc[megaoutput['name']==window_name].iloc[0]\n",
    "    wig_values = rbp_wig_cov.fetch(row['chrom'], row['start'], row['end'], row['strand'])\n",
    "    wig_values_cits = rbp_wig_cits.fetch(row['chrom'], row['start'], row['end'], row['strand'])\n",
    "\n",
    "    seq_values = one_hot[index,:,:] # [1,4,100]\n",
    "    gradient_values = gs[index,0,:,:].cpu().numpy() # [1,1,100,4]\n",
    "    saliency_values = gradient_values * seq_values.T # 4*100\n",
    "    saliency_df = pd.DataFrame(saliency_values.T)\n",
    "    saliency_df.index = list(index2seq)\n",
    "\n",
    "    saliency_df = saliency_df.loc[:, seq_values.sum(axis = 0)!=0].T\n",
    "    saliency_df.index = np.arange(saliency_df.shape[0])\n",
    "\n",
    "    f, ax = plt.subplots(2,1, sharex = True, figsize = (12,4))\n",
    "    logomaker.Logo(saliency_df, # only plot places with sequence\n",
    "                              shade_below=.5,\n",
    "                              fade_below=.5,\n",
    "                              font_name='Arial Rounded MT Bold', \n",
    "                  ax = ax[0])\n",
    "\n",
    "\n",
    "    ax[0].set_ylabel('saliency')\n",
    "    ax[1].bar(np.arange(len(wig_values)), wig_values, color = 'lightgrey')\n",
    "    ax[1].set_ylabel('coverage')\n",
    "#     ax[2].bar(np.arange(len(wig_values_cits)), wig_values_cits, color = 'lightgrey')\n",
    "#     ax[2].plot(gaussian_filter1d(wig_values_cits, 3), color = 'tomato', label = 'smoothed CITS')\n",
    "#     ax[2].set_ylabel('#CITS')\n",
    "\n",
    "    ax[0].set_title(row['chrom'] + ':'+str(row['start'])+'-'+str(row['end'])+':'+row['strand'])\n",
    "    sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ddca181f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0                                                            62\n",
       "CHROM                                                              chr22\n",
       "POS                                                             16611570\n",
       "ID                                                          rs1406598158\n",
       "REF                                                              ACCCCCT\n",
       "ALT                                                                    A\n",
       "name                                                             5573220\n",
       "variant_seq            CACCAGAGAACAATTGACTGTAATTTTCCATTACCTTCCCAAATCC...\n",
       "feature_type_top                                                 SS3_ADJ\n",
       "feature_types                                    SS3_ADJ:SS3_PROX:INTRON\n",
       "gene_name                                              TPTEP1:AC005301.9\n",
       "transcript_types                             lncRNA:processed_transcript\n",
       "transcript_type_top                                               lncRNA\n",
       "INFO/AC                                                                7\n",
       "INFO/AN                                                           151962\n",
       "variant_score_SF3B4                                              2.12383\n",
       "wt_score_SF3B4                                                  4.864162\n",
       "delta_score                                                    -2.740332\n",
       "MAF                                                             0.000046\n",
       "Name: 61, dtype: object"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg_selected_var.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6a1da5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq['rbp_idx'] = np.arange(seq.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8044cf3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "121224    1\n",
       "Name: rbp_idx, dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq.loc[seq['name']==neg_selected_var.iloc[0]['name'], 'rbp_idx'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b87734e",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_saliency(saliency_wt, 0, seq, one_hot_wt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5f02cc63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['Arial Rounded MT Bold'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5573220\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_saliency(saliency_var, 0, neg_selected_var, one_hot_negvar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f1442c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_var_df = pd.DataFrame(y_pred_var, index = variants.index, columns = target_df.columns)\n",
    "y_pred_wt_df = pd.DataFrame(y_pred, index = seq['name'], columns = target_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977f00e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map to variants dataframe\n",
    "rbp = 'SF3B4'\n",
    "variants[f'variant_score_{rbp}'] = y_pred_var_df[f'logLR:{outstem}.{rbp}']\n",
    "variants[f'wt_score_{rbp}'] = variants['name'].map(y_pred_wt_df[f'logLR:{outstem}.{rbp}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cfd2a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants[f'wt_score_{rbp}'].plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea647b",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants.plot.scatter(x = f'wt_score_{rbp}', y = f'variant_score_{rbp}', figsize = (3,3))\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3aad05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants['delta_score'] = (variants[f'variant_score_{rbp}']-variants[f'wt_score_{rbp}'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce508057",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants['delta_score'].hist(bins = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d382c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants['MAF']=(variants['INFO/AC']/variants['INFO/AN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e72962e",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants = variants.loc[variants['INFO/AC']>0]\n",
    "variants['MAF_bin']= pd.cut(variants['MAF'], bins = [0,0.001, 0.01, 1]).astype(str)\n",
    "variants.loc[variants['INFO/AC']==1, 'MAF_bin']='singleton'\n",
    "#variants.loc[variants['INFO/AC']==0, 'MAF_bin']='zero'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6c16314",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants['MAF_bin'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4c76fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants['MAF_bin'] = pd.Categorical(variants['MAF_bin'], categories=['singleton', '(0.0, 0.001]', '(0.001, 0.01]', '(0.01, 1.0]']\n",
    "                                     , ordered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff9b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants.boxplot(by = 'MAF_bin', column = f'wt_score_{rbp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62ec270",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants.boxplot(by = 'MAF_bin', column = f'variant_score_{rbp}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cc901d",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants.boxplot(by = 'MAF_bin', column = 'delta_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1bd15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import  statsmodels.api as sm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36394e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for name, group in variants.loc[variants['delta_score']<0].groupby(by = ['feature_type_top']):\n",
    "    group['MAF_bin_rank'] = group['MAF_bin'].cat.codes\n",
    "#     group.boxplot(by = 'MAF_bin', column = 'delta_score')\n",
    "#     plt.title(name)\n",
    "    mod = sm.OLS(group['delta_score'], group['MAF_bin_rank'])\n",
    "\n",
    "    res = mod.fit()\n",
    "    \n",
    "    results.append([res.pvalues['MAF_bin_rank'], res.params['MAF_bin_rank'], name])\n",
    "results = pd.DataFrame(results, columns = ['pvalue', 'coef', 'feature_type_top'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aea9981",
   "metadata": {},
   "outputs": [],
   "source": [
    "group.plot.scatter('MAF_bin_rank', 'delta_score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2e8200",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.stats.multitest import fdrcorrection\n",
    "results.dropna(subset = ['pvalue'], inplace = True)\n",
    "_,results['FDR'] = fdrcorrection(results['pvalue'])\n",
    "results.sort_values(by = 'FDR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5c320b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58308c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (3,3))\n",
    "sns.stripplot(data = variants.loc[(variants['feature_type_top']=='EXON_MRNA')],\n",
    "              x = 'MAF_bin', y = 'delta_score', ax = ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.hlines(xmin = 0, xmax = 3,y=0, linestyles = 'dotted', color = 'black')\n",
    "# x = np.arange(1,5)\n",
    "# y = results.loc[results['feature_type_top']=='SS3_ADJ', 'coef'].values[0]*x\n",
    "# plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462a44b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (3,3))\n",
    "sns.stripplot(data = variants.loc[(variants['feature_type_top']=='SS3_ADJ')],\n",
    "              x = 'MAF_bin', y = 'delta_score', ax = ax, marker = '.', color = 'grey')\n",
    "plt.xticks(rotation=90)\n",
    "plt.hlines(xmin = 0, xmax = 3,y=0, linestyles = 'dotted', color = 'black')\n",
    "# x = np.arange(1,5)\n",
    "# y = results.loc[results['feature_type_top']=='SS3_ADJ', 'coef'].values[0]*x\n",
    "# plt.plot(x,y)\n",
    "sns.despine()\n",
    "plt.ylabel('delta binding (ALT-REF)')\n",
    "plt.title('SS3_ADJ SF3B4')\n",
    "plt.savefig('SS3_ADJ.SF3B4.score.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438a37ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (3,3))\n",
    "sns.stripplot(data = variants.loc[(variants['feature_type_top']=='SS3_PROX')],\n",
    "              x = 'MAF_bin', y = 'delta_score', ax = ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.hlines(xmin = 0, xmax = 3,y=0, linestyles = 'dotted', color = 'black')\n",
    "# x = np.arange(1,5)\n",
    "# y = results.loc[results['feature_type_top']=='SS3_ADJ', 'coef'].values[0]*x\n",
    "# plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a33e8566",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "for name, group in variants.groupby(by = ['gene_name']):\n",
    "    group['MAF_bin_rank'] = group['MAF_bin'].cat.codes\n",
    "#     group.boxplot(by = 'MAF_bin', column = 'delta_score')\n",
    "#     plt.title(name)\n",
    "    mod = sm.OLS(group['delta_score'], group['MAF_bin_rank'])\n",
    "\n",
    "    res = mod.fit()\n",
    "    \n",
    "    results.append([res.pvalues['MAF_bin_rank'], res.params['MAF_bin_rank'], name])\n",
    "results = pd.DataFrame(results, columns = ['pvalue', 'coef', 'gene_name'])\n",
    "_,results['FDR'] = fdrcorrection(results['pvalue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c55e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.sort_values(by = 'FDR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf8b669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(figsize = (3,3))\n",
    "sns.stripplot(data = variants.loc[(variants['gene_name']=='TOP3B')],\n",
    "              x = 'MAF_bin', y = 'delta_score', ax = ax)\n",
    "plt.xticks(rotation=90)\n",
    "plt.hlines(xmin = 0, xmax = 3,y=0, linestyles = 'dotted', color = 'black')\n",
    "# x = np.arange(1,5)\n",
    "# y = results.loc[results['feature_type_top']=='SS3_ADJ', 'coef'].values[0]*x\n",
    "# plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33df2ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants.loc[variants['gene_name']=='MIATNB'].boxplot(by = 'MAF_bin', \n",
    "                                                             column = 'delta_score',\n",
    "                                                            figsize = (3,3), rot = 90)\n",
    "x = np.arange(1,5)\n",
    "y = results.loc[results['gene_name']=='MIATNB', 'coef'].values[0]*x\n",
    "plt.plot(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c4cae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "variants.loc[variants['gene_name']=='MIATNB', ['feature_type_top', 'ALT', 'REF', 'CHROM', 'POS']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a715bf4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearsondf_region = pd.read_csv(f'../data/ABC_data/{outstem}.mask.pearsonr.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9696f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "perf = pearsondf_region.merge(pearsondf, left_on = ['RBP'], right_on = ['RBP'], suffixes = ('_masked', '_masked&weighted')\n",
    "                      )\n",
    "perf.plot.scatter(x = 'pearsonr_masked', y = 'pearsonr_masked&weighted')\n",
    "plt.plot([0,1], [0,1])\n",
    "sns.despine()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8247744c",
   "metadata": {},
   "outputs": [],
   "source": [
    "perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb61fb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
